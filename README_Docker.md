# Pipeline de Scraping con Docker

Este proyecto automatiza el scraping de productos Samsung de √âxito y Falabella, con verificaci√≥n de datos y subida a Firebase, todo corriendo en un contenedor Docker.

## üöÄ Inicio R√°pido

### Prerrequisitos
- Docker instalado
- Docker Compose instalado
- Archivo `firebase-credentials.json` (opcional, para subida a Firebase)

### Construcci√≥n y Ejecuci√≥n

```bash
# Construir la imagen
docker-compose build

# Ejecutar el pipeline completo
docker-compose up

# Ejecutar en segundo plano
docker-compose up -d

# Ver logs en tiempo real
docker-compose logs -f scraper
```

## üìÅ Estructura de Archivos

```
scraping/
‚îú‚îÄ‚îÄ Dockerfile                 # Imagen Docker con todas las dependencias
‚îú‚îÄ‚îÄ docker-compose.yml         # Orquestaci√≥n del contenedor
‚îú‚îÄ‚îÄ run_pipeline.sh           # Script principal que ejecuta todo el pipeline
‚îú‚îÄ‚îÄ scraper_exito.py          # Scraper de √âxito
‚îú‚îÄ‚îÄ scraper_falabella.py      # Scraper de Falabella
‚îú‚îÄ‚îÄ verificar_productos.py    # Verificaci√≥n y limpieza de datos
‚îú‚îÄ‚îÄ firebase_uploader_organizado.py  # Subida a Firebase
‚îú‚îÄ‚îÄ firebase-credentials.json # Credenciales Firebase (crear manualmente)
‚îú‚îÄ‚îÄ data/                     # Salidas limpias e inv√°lidas (montado desde host)
‚îú‚îÄ‚îÄ backup/                   # Backups autom√°ticos (montado desde host)
‚îî‚îÄ‚îÄ logs/                     # Logs del pipeline (montado desde host)
```

## üîß Configuraci√≥n

### Firebase (Opcional)
1. Ve a [Firebase Console](https://console.firebase.google.com/)
2. Proyecto > Configuraci√≥n > Cuentas de servicio
3. Genera una nueva clave privada
4. Descarga el archivo JSON y ren√≥mbralo a `firebase-credentials.json`
5. Col√≥calo en la carpeta del proyecto

### Variables de Entorno
Puedes modificar el `docker-compose.yml` para agregar variables:

```yaml
environment:
  - TZ=America/Bogota          # Zona horaria
  - MAX_PAGINAS=2              # P√°ginas m√°ximas por scraper
  - DELAY_ENTRE_BUSQUEDAS=60   # Segundos entre b√∫squedas
```

## üéØ Pipeline Automatizado

El script `run_pipeline.sh` ejecuta en orden:

1. **üîß Configuraci√≥n de entorno**: Verifica Python y dependencias
2. **üì¶ Instalaci√≥n**: Playwright, pandas, Firebase admin, etc.
3. **üåê Navegadores**: Descarga Chromium para scraping
4. **üõí Scraper √âxito**: Extrae productos de √âxito
5. **üõçÔ∏è Scraper Falabella**: Extrae productos de Falabella
6. **‚úÖ Verificaci√≥n**: Limpia datos y separa v√°lidos/inv√°lidos
7. **‚òÅÔ∏è Firebase**: Sube datos organizados (si hay credenciales)

## üìä Salidas

### Archivos Generados
- `resultados_exito.xlsx` - Datos crudos de √âxito
- `resultados_falabella.xlsx` - Datos crudos de Falabella
- `data/exito_limpio.xlsx` - Productos v√°lidos de √âxito
- `data/exito_invalidos.xlsx` - Productos inv√°lidos de √âxito
- `data/falabella_limpio.xlsx` - Productos v√°lidos de Falabella
- `data/falabella_invalidos.xlsx` - Productos inv√°lidos de Falabella

### Firebase Collections
- `productos_scraping` - Colecci√≥n principal
- `productos_por_comercio/[comercio]/productos/`
- `productos_por_modelo/[modelo]/productos/`
- `productos_por_vendedor/[vendedor]/productos/`

## üê≥ Comandos Docker √ötiles

```bash
# Ver contenedores en ejecuci√≥n
docker ps

# Acceder al contenedor
docker-compose exec scraper bash

# Ver logs espec√≠ficos
docker-compose logs scraper

# Parar y limpiar
docker-compose down

# Reconstruir imagen
docker-compose build --no-cache

# Ver espacio usado
docker system df

# Limpiar contenedores e im√°genes no usadas
docker system prune
```

## üîç Troubleshooting

### Problema: No se generan archivos
```bash
# Verificar permisos de vol√∫menes
docker-compose exec scraper ls -la /app/data

# Verificar logs del contenedor
docker-compose logs scraper
```

### Problema: Error de Firebase
```bash
# Verificar que el archivo de credenciales existe
docker-compose exec scraper ls -la firebase-credentials.json

# Verificar formato del JSON
docker-compose exec scraper python3 -c "import json; print('Valid' if json.load(open('firebase-credentials.json')) else 'Invalid')"
```

### Problema: Scrapers fallan
```bash
# Verificar que Playwright est√° instalado
docker-compose exec scraper playwright --version

# Probar navegador manualmente
docker-compose exec scraper python3 -c "from playwright.sync_api import sync_playwright; print('OK')"
```

## ‚ö° Ejecuci√≥n Programada

### Con Docker + Cron (Host)
```bash
# Editar crontab
crontab -e

# Ejecutar cada d√≠a a las 6:00 AM
0 6 * * * cd /path/to/scraping && docker-compose up --abort-on-container-exit
```

### Con Docker Compose (Reinicio autom√°tico)
```yaml
# En docker-compose.yml
restart: unless-stopped
```

## üìà Monitoreo

### Logs en tiempo real
```bash
docker-compose logs -f scraper | grep -E "(OK|ERROR|WARN)"
```

### Verificar recursos
```bash
docker stats scraping-pipeline
```

## üöÄ Optimizaci√≥n

### Para mejor rendimiento:
- Aumenta memoria en `docker-compose.yml`
- Usa SSD para vol√∫menes
- Ejecuta en horarios de menor carga de red

### Para debugging:
- Cambia `CMD` en Dockerfile a `CMD ["bash"]`
- Ejecuta comandos manualmente dentro del contenedor
